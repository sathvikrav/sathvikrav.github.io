{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing Text as Vectors\n",
    "\n",
    "_The starting point of NLP is to encode text into numerical featues that can be consumed by statistical models._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = '''I consider John Woo to be one of the greatest action movie directors in the world,and \"Face/Off\" proves just that. \n",
    "However,the element that makes this film one of the most intense and spectacular action movies to ever come from \n",
    "Hollywood is the presence of two tremendously talented actors,both of whom are my favorites.\n",
    "Yes, when you have John Travolta and Nicholas Cage together in a movie ,the results are bound to be over the top.\n",
    "John Travolta plays Sean Archer,a dedicated FBI agent who survived a murder attempt by notorious criminal\n",
    "Castor Troy six years ago. However,tragically his son died instead of him and since than Archer is relentlessly\n",
    "chasing Troy.Nicholas Cage plays Troy,and the film begins with a spectacular chase where we see the sheer intensity\n",
    "generated by both these great actors,and you realize that this is not going to be just another action flick.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _How do you transform text into standardized vectors?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [\n",
    "        [0, 1, 1.3],\n",
    "        [0, 0, 0.2],\n",
    "        [1, 0, 3.2],\n",
    "        [1, 1, 2.1],\n",
    "    ]\n",
    "\n",
    "y = [\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "    ]\n",
    "\n",
    "LogisticRegression().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Problem\n",
    "\n",
    "#### How do you build a classifier to determine if the sentiment of a movie review is positive or negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words (BoW) Model\n",
    "\n",
    "Sentences can be transformed into vectors by:\n",
    "\n",
    "1) building a dictionary of words/tokens based on your data\n",
    "\n",
    "2) transform sentences into numerical representations of word occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"great movie\",\n",
    "    \"good movie\",\n",
    "    \"bad movie\",\n",
    "    \"awful movie\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>awful</th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   awful  bad  good  great  movie\n",
       "0      0    0     0      1      1\n",
       "1      0    0     1      0      1\n",
       "2      0    1     0      0      1\n",
       "3      1    0     0      0      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "'''\n",
    "    The .fit() method of the CountVectorizer is building the token dictionary from training data.\n",
    "'''\n",
    "cv.fit(sentences)\n",
    "\n",
    "'''\n",
    "    The .transform() method of the CountVectorizer is converting sentences into vectors based\n",
    "    on the dictionary.\n",
    "'''\n",
    "word_sentence_matrix = cv.transform(sentences)\n",
    "\n",
    "sentences_df = pd.DataFrame(word_sentence_matrix.toarray(), columns=cv.get_feature_names())\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['awful', 'bad', 'good', 'great', 'movie']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('tokens:', cv.get_feature_names())\n",
    "word_sentence_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning token weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[0 0 0 1 1]\n",
      " [0 0 1 0 1]\n",
      " [0 1 0 0 1]\n",
      " [1 0 0 0 1]]\n",
      "\n",
      "y:\n",
      " [1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"great movie\",\n",
    "    \"good movie\",\n",
    "    \"bad movie\",\n",
    "    \"awful movie\",\n",
    "]\n",
    "\n",
    "'''\n",
    "    Binary Sentiment:\n",
    "        - 1: positive\n",
    "        - 0: negative\n",
    "'''\n",
    "sentiment = [\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "]\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(sentences)\n",
    "y = sentiment\n",
    "print('X:\\n', X.toarray())\n",
    "print()\n",
    "print('y:\\n', y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 0.4010569669628933),\n",
       " ('great', 0.4010569669628933),\n",
       " ('movie', 0.0),\n",
       " ('awful', -0.4010569669628933),\n",
       " ('bad', -0.4010569669628933)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bow_classifier = LogisticRegression()\n",
    "lr_bow_classifier.fit(X,y)\n",
    "\n",
    "sorted(list(zip(cv.get_feature_names(), lr_bow_classifier.coef_[0])), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bow_classifier.predict(cv.transform([\"it was great\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bow_classifier.predict(cv.transform([\"it was bad\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Vectorization Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-processing Methods\n",
    "\n",
    "Reducing noise in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>awful</th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>it</th>\n",
       "      <th>like</th>\n",
       "      <th>liked</th>\n",
       "      <th>movie</th>\n",
       "      <th>okay</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   an  awful  bad  good  it  like  liked  movie  okay  the  this  was\n",
       "0   0      0    1     0   1     0      0      1     0    0     0    1\n",
       "1   0      0    0     0   1     0      0      1     1    0     0    1\n",
       "2   1      1    0     0   1     0      0      1     0    0     0    1\n",
       "3   0      0    0     1   1     0      0      1     0    0     0    1\n",
       "4   0      0    0     0   0     1      0      1     0    1     0    0\n",
       "5   0      0    0     0   0     0      1      1     1    0     1    0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [    \n",
    "    \"it was a bad movie\",\n",
    "    \"it was a okay movie\",\n",
    "    \"it was an awful movie\",\n",
    "\n",
    "    \"it was a good movie\",\n",
    "    \"i like the movie\",\n",
    "    \"i liked this movie okay\",\n",
    "]\n",
    "\n",
    "sentiment = [\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "]\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(sentences)\n",
    "word_sentence_matrix = cv.transform(sentences)\n",
    "sentences_df = pd.DataFrame(word_sentence_matrix.toarray(), columns=cv.get_feature_names())\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 14.119732285923776),\n",
       " ('this', 5.41464426861084),\n",
       " ('the', 5.168892533138319),\n",
       " ('like', 1.737862245510235),\n",
       " ('liked', 1.4921105100377128),\n",
       " ('an', 0.0),\n",
       " ('awful', 0.0),\n",
       " ('bad', 0.0),\n",
       " ('movie', 0.0),\n",
       " ('okay', 0.0),\n",
       " ('it', -3.2596939285842645),\n",
       " ('was', -4.017981926568795)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(sentences)\n",
    "y = sentiment\n",
    "\n",
    "lr_bow_classifier = LogisticRegression(penalty='l1', C=1000, solver='liblinear')\n",
    "lr_bow_classifier.fit(X,y)\n",
    "\n",
    "sorted(list(zip(cv.get_feature_names(), lr_bow_classifier.coef_[0])), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00565867, 0.99434133]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bow_classifier.predict_proba(cv.transform([\"the\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96301989, 0.03698011]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bow_classifier.predict_proba(cv.transform([\"it\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bow_classifier.predict_proba(cv.transform([\"bad\"]).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keeping stopwords can add noise to models:\n",
    "\n",
    "- this model has learned that \"the\" is a positive sentiment term and \"it\" is a negative sentiment term\n",
    "- Due to some of these confusions, it has also learned weights suggesting that \"bad\" is neither negative or positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing methods: stop words\n",
    "\n",
    "_Remove noise from your data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('liked', 0.432),\n",
       " ('good', 0.426),\n",
       " ('like', 0.357),\n",
       " ('the', 0.357),\n",
       " ('movie', 0.0),\n",
       " ('okay', -0.03),\n",
       " ('awful', -0.377),\n",
       " ('bad', -0.377)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words=['it', 'an', 'was', 'this'])\n",
    "\n",
    "'''\n",
    "Many libraries come with standard stop words baked in:\n",
    "    \n",
    "    cv = CountVectorizer(stop_words='english')\n",
    "'''\n",
    "\n",
    "X = cv.fit_transform(sentences)\n",
    "y = sentiment\n",
    "\n",
    "lr_bow_classifier = LogisticRegression(random_state=0)\n",
    "lr_bow_classifier.fit(X,y)\n",
    "\n",
    "sorted(list(zip(cv.get_feature_names(), np.round(lr_bow_classifier.coef_[0], 3))), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing: Token Frequency Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad  good\n",
       "0    0     1\n",
       "1    0     1\n",
       "2    1     0\n",
       "3    1     0\n",
       "4    0     0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [    \n",
    "    \"it was a good movie\",\n",
    "    \"it was a very good movie\",\n",
    "    \"it was an bad movie\",\n",
    "\n",
    "    \"it was a bad movie\",\n",
    "    \"it was a terrible movie\",\n",
    "]\n",
    "cv = CountVectorizer(\n",
    "    min_df = 2, # absolute threshold\n",
    "    max_df = 0.9, # ratio threshold,\n",
    "    stop_words='english'\n",
    ")\n",
    "cv.fit(sentences)\n",
    "word_sentence_matrix = cv.transform(sentences)\n",
    "sentences_df = pd.DataFrame(word_sentence_matrix.toarray(), columns=cv.get_feature_names())\n",
    "sentences_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing: Word Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"great movie\",\n",
    "    \"good movie\",\n",
    "    \"bad movie\",\n",
    "    \"awful movie\",\n",
    "]\n",
    "cv = CountVectorizer().fit(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([\n",
    "    'great'\n",
    "]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Unseen tokens are ignored after the dictionary is built\n",
    "'''\n",
    "cv.transform([\n",
    "    'greatest'\n",
    "]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>great</th>\n",
       "      <th>greatest</th>\n",
       "      <th>it</th>\n",
       "      <th>movie</th>\n",
       "      <th>the</th>\n",
       "      <th>very</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad  great  greatest  it  movie  the  very  was\n",
       "0    0      1         0   1      1    0     0    1\n",
       "1    0      0         1   1      1    1     0    1\n",
       "2    1      0         0   1      1    0     0    1\n",
       "3    1      0         0   1      1    0     1    1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [    \n",
    "    \"it was a great movie\",\n",
    "    \"it was the greatest movie\",\n",
    "    \n",
    "    \"it was a bad movie\",\n",
    "    \"it was a very bad movie\",\n",
    "]\n",
    "\n",
    "sentiment = [\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "]\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(sentences)\n",
    "word_sentence_matrix = cv.transform(sentences)\n",
    "sentences_df = pd.DataFrame(word_sentence_matrix.toarray(), columns=cv.get_feature_names())\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.366), ('greatest', 0.366), ('movie', -0.0), ('bad', -0.732)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "X = cv.fit_transform(sentences)\n",
    "y = sentiment\n",
    "\n",
    "lr_bow_classifier = LogisticRegression(random_state=0)\n",
    "lr_bow_classifier.fit(X,y)\n",
    "\n",
    "sorted(list(zip(cv.get_feature_names(), np.round(lr_bow_classifier.coef_[0], 3))), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run : run\n",
      "running : run\n",
      "runs : run\n",
      "ran : ran\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "for token in ['run', 'running', 'runs', 'ran']:\n",
    "    print(token, ':', stemmer.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N grams\n",
    "\n",
    "Tokens as compounds of words using N-gram ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "unit\n",
      "state\n",
      "of\n",
      "america\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the united states of america \"\n",
    "\n",
    "for token in sentence.split(' '):\n",
    "    print(stemmer.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### n-gram range (1,2)\n",
    "'''\n",
    "    ['the', 'the united', 'united', 'united states', 'states', 'states of', ...]\n",
    "'''\n",
    "\n",
    "### n-gram range (1,3)\n",
    "'''\n",
    "    ['the', 'the united', 'the united states', 'united', 'united states', 'united states of', ...]\n",
    "'''\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I consider John Woo to be one of the greatest action movie directors in the world,and \"Face/Off\" proves just that. \\nHowever,the element that makes this film one of the most intense and spectacular action movies to ever come from \\nHollywood is the presence of two tremendously talented actors,both of whom are my favorites.\\nYes, when you have John Travolta and Nicholas Cage together in a movie ,the results are bound to be over the top.\\nJohn Travolta plays Sean Archer,a dedicated FBI agent who survived a murder attempt by notorious criminal\\nCastor Troy six years ago. However,tragically his son died instead of him and since than Archer is relentlessly\\nchasing Troy.Nicholas Cage plays Troy,and the film begins with a spectacular chase where we see the sheer intensity\\ngenerated by both these great actors,and you realize that this is not going to be just another action flick.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['action',\n",
       " 'action flick',\n",
       " 'action movie',\n",
       " 'action movie directors',\n",
       " 'action movies',\n",
       " 'action movies come',\n",
       " 'actors',\n",
       " 'actors favorites',\n",
       " 'actors realize',\n",
       " 'actors realize going',\n",
       " 'agent',\n",
       " 'agent survived',\n",
       " 'agent survived murder',\n",
       " 'ago',\n",
       " 'archer',\n",
       " 'archer dedicated',\n",
       " 'archer dedicated fbi',\n",
       " 'archer relentlessly',\n",
       " 'archer relentlessly chasing',\n",
       " 'attempt',\n",
       " 'attempt notorious',\n",
       " 'attempt notorious criminal',\n",
       " 'begins',\n",
       " 'begins spectacular',\n",
       " 'begins spectacular chase',\n",
       " 'bound',\n",
       " 'cage',\n",
       " 'cage movie',\n",
       " 'cage movie results',\n",
       " 'cage plays',\n",
       " 'cage plays troy',\n",
       " 'castor',\n",
       " 'castor troy',\n",
       " 'castor troy years',\n",
       " 'chase',\n",
       " 'chase sheer',\n",
       " 'chase sheer intensity',\n",
       " 'chasing',\n",
       " 'chasing troy',\n",
       " 'come',\n",
       " 'come hollywood',\n",
       " 'come hollywood presence',\n",
       " 'consider',\n",
       " 'consider john',\n",
       " 'consider john woo',\n",
       " 'criminal',\n",
       " 'criminal castor',\n",
       " 'criminal castor troy',\n",
       " 'dedicated',\n",
       " 'dedicated fbi',\n",
       " 'dedicated fbi agent',\n",
       " 'died',\n",
       " 'died instead',\n",
       " 'died instead archer',\n",
       " 'directors',\n",
       " 'directors world',\n",
       " 'directors world face',\n",
       " 'element',\n",
       " 'element makes',\n",
       " 'element makes film',\n",
       " 'face',\n",
       " 'face proves',\n",
       " 'face proves just',\n",
       " 'favorites',\n",
       " 'fbi',\n",
       " 'fbi agent',\n",
       " 'fbi agent survived',\n",
       " 'film',\n",
       " 'film begins',\n",
       " 'film begins spectacular',\n",
       " 'film intense',\n",
       " 'film intense spectacular',\n",
       " 'flick',\n",
       " 'generated',\n",
       " 'generated great',\n",
       " 'generated great actors',\n",
       " 'going',\n",
       " 'going just',\n",
       " 'going just action',\n",
       " 'great',\n",
       " 'great actors',\n",
       " 'great actors realize',\n",
       " 'greatest',\n",
       " 'greatest action',\n",
       " 'greatest action movie',\n",
       " 'hollywood',\n",
       " 'hollywood presence',\n",
       " 'hollywood presence tremendously',\n",
       " 'instead',\n",
       " 'instead archer',\n",
       " 'instead archer relentlessly',\n",
       " 'intense',\n",
       " 'intense spectacular',\n",
       " 'intense spectacular action',\n",
       " 'intensity',\n",
       " 'intensity generated',\n",
       " 'intensity generated great',\n",
       " 'john',\n",
       " 'john travolta',\n",
       " 'john travolta nicholas',\n",
       " 'john travolta plays',\n",
       " 'john woo',\n",
       " 'john woo greatest',\n",
       " 'just',\n",
       " 'just action',\n",
       " 'just action flick',\n",
       " 'makes',\n",
       " 'makes film',\n",
       " 'makes film intense',\n",
       " 'movie',\n",
       " 'movie directors',\n",
       " 'movie directors world',\n",
       " 'movie results',\n",
       " 'movie results bound',\n",
       " 'movies',\n",
       " 'movies come',\n",
       " 'movies come hollywood',\n",
       " 'murder',\n",
       " 'murder attempt',\n",
       " 'murder attempt notorious',\n",
       " 'nicholas',\n",
       " 'nicholas cage',\n",
       " 'nicholas cage movie',\n",
       " 'nicholas cage plays',\n",
       " 'notorious',\n",
       " 'notorious criminal',\n",
       " 'notorious criminal castor',\n",
       " 'plays',\n",
       " 'plays sean',\n",
       " 'plays sean archer',\n",
       " 'plays troy',\n",
       " 'plays troy film',\n",
       " 'presence',\n",
       " 'presence tremendously',\n",
       " 'presence tremendously talented',\n",
       " 'proves',\n",
       " 'proves just',\n",
       " 'realize',\n",
       " 'realize going',\n",
       " 'realize going just',\n",
       " 'relentlessly',\n",
       " 'relentlessly chasing',\n",
       " 'relentlessly chasing troy',\n",
       " 'results',\n",
       " 'results bound',\n",
       " 'sean',\n",
       " 'sean archer',\n",
       " 'sean archer dedicated',\n",
       " 'sheer',\n",
       " 'sheer intensity',\n",
       " 'sheer intensity generated',\n",
       " 'son',\n",
       " 'son died',\n",
       " 'son died instead',\n",
       " 'spectacular',\n",
       " 'spectacular action',\n",
       " 'spectacular action movies',\n",
       " 'spectacular chase',\n",
       " 'spectacular chase sheer',\n",
       " 'survived',\n",
       " 'survived murder',\n",
       " 'survived murder attempt',\n",
       " 'talented',\n",
       " 'talented actors',\n",
       " 'talented actors favorites',\n",
       " 'tragically',\n",
       " 'tragically son',\n",
       " 'tragically son died',\n",
       " 'travolta',\n",
       " 'travolta nicholas',\n",
       " 'travolta nicholas cage',\n",
       " 'travolta plays',\n",
       " 'travolta plays sean',\n",
       " 'tremendously',\n",
       " 'tremendously talented',\n",
       " 'tremendously talented actors',\n",
       " 'troy',\n",
       " 'troy film',\n",
       " 'troy film begins',\n",
       " 'troy years',\n",
       " 'troy years ago',\n",
       " 'woo',\n",
       " 'woo greatest',\n",
       " 'woo greatest action',\n",
       " 'world',\n",
       " 'world face',\n",
       " 'world face proves',\n",
       " 'years',\n",
       " 'years ago',\n",
       " 'yes',\n",
       " 'yes john',\n",
       " 'yes john travolta']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,3)).fit(raw_text.split('.'))\n",
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['action',\n",
       " 'actors',\n",
       " 'archer',\n",
       " 'cage',\n",
       " 'film',\n",
       " 'john',\n",
       " 'john travolta',\n",
       " 'just',\n",
       " 'movie',\n",
       " 'nicholas',\n",
       " 'nicholas cage',\n",
       " 'plays',\n",
       " 'spectacular',\n",
       " 'travolta',\n",
       " 'troy']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,3), min_df=2).fit(raw_text.split('.'))\n",
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much data do you need to train an NLP model?\n",
    "\n",
    "#### Unfortunately no clear rule of thumb.. Using cross fold validation and other evaluation methods will help understand your use case. But..\n",
    "\n",
    "- Learning token weights (treating features as independent) at LEAST\n",
    "    * 100 words in dictionary.. x 10 records per feature = 1,000 records\n",
    "    * 1,000 words in dictionary.. x 10 records per feature = 10,000 records\n",
    "\n",
    "\n",
    "- Classifying documents (treating features as dependent)\n",
    "    * 1000 words in dictionary x 100 records per feature = 100,000 records\n",
    "    * 10,000 words in dictionary x 100 records per feature = 1,000,000 records\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word / Document Vectors (Embeddings)\n",
    "\n",
    "_Moving from bag of words to word vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensorflow Wikipedia Word2Vec Projector\n",
    "\n",
    "https://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####    Developed by training models to predict relationships of words:\n",
    "    \n",
    "- \"the dog chased the: {?}\"\n",
    "- \"the dog {?} the cat\"\n",
    "- \"the {?} chased the cat\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x11c0a7e50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "model = api.load(\"glove-wiki-gigaword-50\")\n",
    "model\n",
    "# model.most_similar(\"glass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.45281 , -0.50108 , -0.53714 , -0.015697,  0.22191 ,  0.54602 ,\n",
       "       -0.67301 , -0.6891  ,  0.63493 , -0.19726 ,  0.33685 ,  0.7735  ,\n",
       "        0.90094 ,  0.38488 ,  0.38367 ,  0.2657  , -0.08057 ,  0.61089 ,\n",
       "       -1.2894  , -0.22313 , -0.61578 ,  0.21697 ,  0.35614 ,  0.44499 ,\n",
       "        0.60885 , -1.1633  , -1.1579  ,  0.36118 ,  0.10466 , -0.78325 ,\n",
       "        1.4352  ,  0.18629 , -0.26112 ,  0.83275 , -0.23123 ,  0.32481 ,\n",
       "        0.14485 , -0.44552 ,  0.33497 , -0.95946 , -0.097479,  0.48138 ,\n",
       "       -0.43352 ,  0.69455 ,  0.91043 , -0.28173 ,  0.41637 , -1.2609  ,\n",
       "        0.71278 ,  0.23782 ], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92180055]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity([model['cat']], [model['dog']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29200307]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([model['cat']], [model['laptop']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear operations with Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8609581]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queen = model['king'] - model['man'] + model['woman']\n",
    "\n",
    "cosine_similarity([queen], [model['queen']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Document Embeddings in Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.140836</td>\n",
       "      <td>0.753965</td>\n",
       "      <td>-0.630695</td>\n",
       "      <td>-0.174898</td>\n",
       "      <td>0.40267</td>\n",
       "      <td>0.051885</td>\n",
       "      <td>-0.382405</td>\n",
       "      <td>-0.312630</td>\n",
       "      <td>-0.252180</td>\n",
       "      <td>0.763297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.223905</td>\n",
       "      <td>0.753775</td>\n",
       "      <td>-0.376610</td>\n",
       "      <td>-0.306865</td>\n",
       "      <td>-0.527170</td>\n",
       "      <td>0.372588</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>-0.739175</td>\n",
       "      <td>-0.368825</td>\n",
       "      <td>0.371665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.106434</td>\n",
       "      <td>-0.135745</td>\n",
       "      <td>-0.425995</td>\n",
       "      <td>-0.209078</td>\n",
       "      <td>0.31976</td>\n",
       "      <td>-0.009200</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>-0.351265</td>\n",
       "      <td>-0.345415</td>\n",
       "      <td>0.914115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.495920</td>\n",
       "      <td>0.544190</td>\n",
       "      <td>-0.079615</td>\n",
       "      <td>-0.178475</td>\n",
       "      <td>-0.376856</td>\n",
       "      <td>0.300144</td>\n",
       "      <td>0.160355</td>\n",
       "      <td>-0.268540</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>0.824085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.320165</td>\n",
       "      <td>0.071936</td>\n",
       "      <td>-0.407420</td>\n",
       "      <td>-0.212798</td>\n",
       "      <td>0.26962</td>\n",
       "      <td>0.170055</td>\n",
       "      <td>0.274435</td>\n",
       "      <td>-0.083535</td>\n",
       "      <td>-0.164740</td>\n",
       "      <td>0.755728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510140</td>\n",
       "      <td>0.628770</td>\n",
       "      <td>0.044895</td>\n",
       "      <td>-0.335534</td>\n",
       "      <td>-0.217745</td>\n",
       "      <td>0.375964</td>\n",
       "      <td>0.028185</td>\n",
       "      <td>-0.419340</td>\n",
       "      <td>0.096940</td>\n",
       "      <td>0.664395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.303740</td>\n",
       "      <td>0.387840</td>\n",
       "      <td>-0.272080</td>\n",
       "      <td>0.153718</td>\n",
       "      <td>0.41566</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>-0.678440</td>\n",
       "      <td>-0.652800</td>\n",
       "      <td>-0.068025</td>\n",
       "      <td>1.128275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173658</td>\n",
       "      <td>0.756765</td>\n",
       "      <td>-0.153992</td>\n",
       "      <td>-0.488380</td>\n",
       "      <td>-0.579760</td>\n",
       "      <td>0.172008</td>\n",
       "      <td>0.233680</td>\n",
       "      <td>-0.518901</td>\n",
       "      <td>-0.123241</td>\n",
       "      <td>0.879575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3        4         5         6   \\\n",
       "0  0.140836  0.753965 -0.630695 -0.174898  0.40267  0.051885 -0.382405   \n",
       "1  0.106434 -0.135745 -0.425995 -0.209078  0.31976 -0.009200 -0.016370   \n",
       "2  0.320165  0.071936 -0.407420 -0.212798  0.26962  0.170055  0.274435   \n",
       "3 -0.303740  0.387840 -0.272080  0.153718  0.41566  0.113419 -0.678440   \n",
       "\n",
       "         7         8         9   ...        40        41        42        43  \\\n",
       "0 -0.312630 -0.252180  0.763297  ... -0.223905  0.753775 -0.376610 -0.306865   \n",
       "1 -0.351265 -0.345415  0.914115  ... -0.495920  0.544190 -0.079615 -0.178475   \n",
       "2 -0.083535 -0.164740  0.755728  ... -0.510140  0.628770  0.044895 -0.335534   \n",
       "3 -0.652800 -0.068025  1.128275  ... -0.173658  0.756765 -0.153992 -0.488380   \n",
       "\n",
       "         44        45        46        47        48        49  \n",
       "0 -0.527170  0.372588 -0.001055 -0.739175 -0.368825  0.371665  \n",
       "1 -0.376856  0.300144  0.160355 -0.268540  0.018505  0.824085  \n",
       "2 -0.217745  0.375964  0.028185 -0.419340  0.096940  0.664395  \n",
       "3 -0.579760  0.172008  0.233680 -0.518901 -0.123241  0.879575  \n",
       "\n",
       "[4 rows x 50 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "\n",
    "sentences = [\n",
    "    \"great movie\",\n",
    "    \"awful movie\",\n",
    "    \"terrible movie\",\n",
    "    \"best movie\",\n",
    "]\n",
    "\n",
    "sentiments = [\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "]\n",
    "\n",
    "def average_document(sentence):\n",
    "    tokens = [token for token in sentence.split(' ') if token not in stop_words]\n",
    "    return np.average([model[token] for token in tokens], axis=0)\n",
    "\n",
    "X = np.array([average_document(s) for s in sentences])\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X, sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    'amazing' is an unseen token\n",
    "'''\n",
    "clf.predict([average_document('amazing movie')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    'worst' is an unseen token\n",
    "'''\n",
    "clf.predict([average_document('worst movie')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use embeddings?\n",
    "\n",
    "- Word / document embeddings are richer representations of text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 2]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizer().fit_transform(['the cat ran over the fence']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05408067, -0.15016332,  0.34357   , -0.00895233,  0.08262666,\n",
       "        0.24126466, -0.86868   , -0.32828102,  0.26363868, -0.62116003,\n",
       "       -0.41942668, -0.15177333, -0.15515666,  0.34706464,  0.018743  ,\n",
       "        0.12498334,  0.18917668,  0.19567998, -0.7870967 , -0.19576333,\n",
       "       -0.01438   ,  0.14882   , -0.17090333,  0.05952001,  0.5412767 ,\n",
       "       -1.3095332 ,  0.10766002,  0.55329996,  0.48070002, -0.8011033 ,\n",
       "        1.8541666 , -0.17321032, -0.17284234,  0.48640335, -0.41412333,\n",
       "        0.25697634,  0.24372673, -0.01935335, -0.09209368, -0.10261667,\n",
       "       -0.15008901,  0.09858632, -0.19396664,  0.49168667,  0.18769   ,\n",
       "       -0.4771267 ,  0.14372334, -1.06508   ,  0.29074666, -0.3884767 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_document('the cat ran over the fence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
